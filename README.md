# ChatBot de ejercicios de parcial ‚Äî Ingreso UTN FRBA

Descripci√≥n del proyecto
- Chatbot orientado a generar ejercicios de matem√°tica con el mismo nivel y estilo que los parciales de ingreso de la UTN FRBA. 
- Devuelve enunciado, pasos de resoluci√≥n y respuesta final en formato estructurado (JSON), citando fuente cuando utiliza el dataset semilla alojado en GitHub.
- Dise√±ado para uso en aula: alumnos avanzados piden ejercicios m√°s dif√≠ciles; quienes necesitan refuerzo eligen ejercicios sencillos. El docente acompa√±a y aclara dudas sobre la resoluci√≥n brindada por el bot.

Definici√≥n del ChatBot
- Problema que resuelve
  - Busca reducir el desnivel con el que se encuentran los alumnos al iniciar las clases en el ingreso de la UTN FRBA, ofreciendo pr√°ctica personalizada con ejercicios ‚Äúestilo parcial‚Äù y retroalimentaci√≥n verificable.
- P√∫blico objetivo
  - Alumnos del ingreso de UTN FRBA y docentes que buscan facilitar pr√°ctica con dificultad adaptativa.
- Propuesta de valor
  - Generaci√≥n continua de ejercicios alineados al examen, con pasos y respuestas verificables; historial persistente; cita de fuente al usar dataset semilla; panel de debug para transparencia t√©cnica.

Links de deploy
- Frontend (Vercel): https://ai-tool-calling-integration.vercel.app

Arquitectura (alto nivel)
```
Frontend (Next.js, Vercel)
   ‚îî‚îÄ‚îÄ UI de chat, historial, bienvenida, debug sheet
        ‚ñ≤
        ‚îÇ HTTP (fetch con credentials; cookies HttpOnly para scoping)
        ‚ñº
Backend (NestJS, Render/Railway)
   ‚îú‚îÄ‚îÄ POST /chat (OpenAI + tools, Zod, persistencia)
   ‚îî‚îÄ‚îÄ GET /conversations, GET /conversations/:id

```

## Tecnolog√≠as principales

- **Lenguaje:** TypeScript (frontend y backend)
- **Frontend:** Next.js (React)
- **Backend:** NestJS (Node.js)
- **Base de datos:** MongoDB Atlas
- **Orquestador LLM y tools:** OpenAI SDK
- **Librer√≠as clave:** 
  - Zod (validaci√≥n de schemas)
  - mathjs (validaci√≥n respuestas num√©ricas)
- **Testing:** Jest, Supertest
- **Control de versiones:** GitHub
- **Despliegue:** 
  - Frontend en Vercel
  - Backend en Render
- **Integraci√≥n API externa:** GitHub Contents API para dataset semilla de ejercicios

---

### Decisiones y justificaci√≥n del stack

- **Next.js**  
  Elegido para el frontend ya que permite desarrollo veloz con React, soporte nativo para SSR y rutas, y despliegue autom√°tico en Vercel seg√∫n lo requerido en la consigna.

- **NestJS**  
  Usado para el backend por su arquitectura modular, escalabilidad y robusta integraci√≥n con herramientas modernas (OpenAI, MongoDB), adem√°s de manejo sencillo de middlewares, validaci√≥n y CORS.

- **MongoDB Atlas**  
  Preferido por sobre una base relacional debido a la baja complejidad de las relaciones entre entidades (conversaciones, mensajes, ejercicios), flexibilidad de modelo y facilidad de despliegue y administraci√≥n. Permite almacenar documentos con schemas evolutivos y acelerar el time-to-market requerido por el challenge.

- **Render y Vercel**  
  Render elegido para el backend por facilidad de uso, builds automatizados y similitud conceptual con Vercel, plataforma obligatoria para el frontend seg√∫n consigna.

- **OpenAI, Zod, mathjs, etc.**  
  OpenAI SDK es el core de la integraci√≥n LLM; Zod y mathjs garantizan que los datos intercambiados sean v√°lidos y robustos tanto en inputs como en outputs.

---
### Tools/APIs elegidas
  - Tool externa: GitHub Contents API
    - Dataset semilla versionado, auditable y de f√°cil acceso. Permite citar fuente y manejar rate limits de forma expl√≠cita. Es una API real distinta al LLM, cumpliendo el requisito y alineada al caso de estudio (ejercicios).
  - Tool interna: validateNumericAnswer (mathjs)
    - Verificaci√≥n determin√≠stica de respuestas num√©ricas del alumno; aporta l√≥gica de negocio y evita delegar todo al LLM.
- Manejo de errores y edge cases
  - Retries con backoff (429/5xx) para llamadas a OpenAI; timeouts para herramientas externas; validaci√≥n con Zod de outputs del LLM y del dataset semilla; fallback a texto si el JSON no valida; logging controlado sin secretos.
- Estrategia de prompts
  - System prompt define reglas: temas/dificultad; formato JSON; pasos y respuesta; uso de tools y cita de fuente.
  - Few-shots para guiar cu√°ndo invocar cada tool (seed/validaci√≥n) y c√≥mo devolver outputs estructurados.
- Trade-offs
  - No se implement√≥ autenticaci√≥n completa; se usa cookie HttpOnly (client_id) para scoping de conversaciones. Es suficiente para el challenge y preserva privacidad b√°sica sin complejidad de auth.
  - Se prioriz√≥ velocidad de entrega y claridad t√©cnica por sobre features avanzadas (SSE/RAG); ambos quedan planificados como mejora futura.

---
### Mejoras futuras planeadas
- Autenticaci√≥n de usuarios y perfil docente/alumno.
- Feedback por mensaje (üëç/üëé), supervisi√≥n docente.
- Internacionalizaci√≥n y soporte para m√°s temas.
- RAG (Retrieval Augmented Generation) con embeddings sobre el dataset semilla.
- Observabilidad avanzada: traces, m√©tricas y panel de insights.
- Filtros y b√∫squeda avanzada en el historial.

---

### User Stories 

1) Como alumno  
   Quiero pedir ejercicios por tema y dificultad  
   Para practicar con el mismo nivel del parcial y mejorar mi rendimiento  
   Criterios de aceptaci√≥n:
   - [ ] Al enviar ‚ÄúGenerame N ejercicios de {tema}, dificultad {baja|media|alta}‚Äù, el bot devuelve JSON con exercises[{topic, difficulty, statement, steps[], answer, source}].
   - [ ] Si se usa el dataset semilla, se cita la fuente (URL de GitHub) en el ejercicio y/o panel de debug.
   - [ ] Se persisten la conversaci√≥n y los ejercicios, y se ven al recargar.

2) Como alumno  
   Quiero validar mi respuesta num√©rica  
   Para confirmar si resolv√≠ correctamente  
   Criterios de aceptaci√≥n:
   - [ ] Al enviar ‚ÄúValid√° mi respuesta: {expr} frente a {expected}‚Äù, el bot usa validateNumericAnswer y responde ok/error.
   - [ ] El resultado se persiste como mensaje del asistente en la conversaci√≥n.

3) Como alumno  
   Quiero ver mi historial de conversaci√≥n  
   Para continuar practicando donde lo dej√©  
   Criterios de aceptaci√≥n:
   - [ ] La sidebar lista mis conversaciones ordenadas por ‚Äú√öltima actividad‚Äù (lastMessageAt).
   - [ ] Al abrir una conversaci√≥n, se muestra la cronolog√≠a intercalada de mensajes y ejercicios (agrupados por messageId).
   - [ ] Las conversaciones se filtran por cookie HttpOnly (client_id), mostrando solo las del usuario actual.
---

### Features implementadas (bonus)
- Tool/function calling nativo (OpenAI) con decisi√≥n autom√°tica.
- JSON estructurado validado con Zod.
- Panel de debug (desktop sidebar y mobile bottom sheet) con herramientas, tokens y latencias.
- Testing: E2E de POST /chat (Jest + Supertest) y unit tests m√≠nimos de tools.
- Accesibilidad: aria-labels en botones clave, foco visible, layout responsivo.
- Rate limiting recomendado: 30 req/5 min en /chat (snippet incluido).

---

### Instalaci√≥n local (monorepo)

Requisitos:
- Node.js >= 18
- pnpm >= 8
- MongoDB Atlas (URI)
- Claves de OpenAI y variables del seed

1) Preparar variables
- Copiar ejemplos de entorno:
  - Backend: `cp apps/backend/.env.example apps/backend/.env`
  - Frontend: `cp apps/frontend/.env.example apps/frontend/.env.local`
- Completar:
  - Backend: OPENAI_API_KEY, MONGODB_URI, FRONTEND_ORIGIN, SEED_OWNER, SEED_REPO, SEED_PATH
  - Frontend: NEXT_PUBLIC_API_URL (URL del backend)

2) Instalar dependencias
- En la ra√≠z: `pnpm install`

3) Levantar backend (NestJS)
- `pnpm -F @app/backend start:dev`
- Por defecto: `http://localhost:3001` (ajustar .env si es distinto)

4) Levantar frontend (Next.js)
- `pnpm -F @app/frontend dev`
- Visitar `http://localhost:3000`
--- 

## Capturas de pantalla

### Bienvenida en desktop

![Bienvenida](./docs/screenshots/bienvenida-desktop.png)

### Ejemplo de generaci√≥n de ejercicios
![Ejercicio generado](./docs/screenshots/ejercicio-generado.png)

### Panel de debug con tools y tokens
![Debug panel](./docs/screenshots/panel-debug.png)

### Mobile
![Mobile](./docs/screenshots/mobile.png)

### Demo animada
![Demo GIF](./docs/prueba.gif)

---

### Modelos y persistencia
- conversations: { title?, userId?, lastMessagePreview?, lastMessageAt?, createdAt, updatedAt }
- messages: { conversationId, role: 'user'|'assistant'|'tool', content, metadata?, createdAt }
- exercises: { conversationId, messageId?, topic, difficulty, statement, steps, answer, sourceUrl?, createdAt }

--- 

### Endpoints principales (backend)
- POST /chat
  - Orquesta OpenAI con tools (GitHub seed, validar respuesta), persiste mensajes y ejercicios.
  - Devuelve JSON de ejercicios o texto y meta (timings, tokens, tools, sourceUrl).
- GET /conversations
  - Lista conversaciones del usuario (cookie HttpOnly client_id), ordenadas por lastMessageAt.
- GET /conversations/:id
  - Devuelve mensajes y ejercicios de la conversaci√≥n (cronolog√≠a intercalada por createdAt/messageId).
---

### Panel de debug (UX)
- Desktop: sidebar derecha fija con estado vac√≠o cuando no hay datos y lista de tools/tokens/timings cuando hay respuesta.
- Mobile: bottom sheet accesible con toggle, estado vac√≠o si a√∫n no hay meta.

---

### Testing
- **E2E Tests**: Prueba del flujo completo de POST /chat (Jest + Supertest) con mocks de OpenAI y tool externa.
  - Correr: `pnpm -F @app/backend test:e2e`
  
- **Unit Tests**: Tests unitarios de las herramientas individuales.
  - Correr: `pnpm -F @app/backend test`
  - Cobertura:
    - `fetchSeedExamplesFromGitHub`: Valida filtrado por topic/difficulty, formato Zod y manejo de rate limit (429)
    - `validateNumericAnswer`: Verifica validaci√≥n correcta de expresiones y manejo de errores

Notas finales
- Se prioriz√≥ una entrega s√≥lida y clara en 4 d√≠as: arquitectura separada (Vercel + Render), persistencia real (Mongo Atlas), tool calling nativo, JSON estructurado y panel de debug transparente.
